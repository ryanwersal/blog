---
title: "ðŸ“š Analyzing Co-Intelligence: Collaborating with AI"
date: 2025-04-24T10:00:00-07:00
draft: false
tags: ["ai", "books", "analysis"]
categories: ["ai"]
---

[Co-Intelligence](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/), written by Ethan Mollick, is a pretty interesting read about what AI means for many aspects of humanity. The overarching themes are that AI currently, and possibly in the near term future, can't replace us. But that doesn't diminish current-gen AI. To the contrary, actively collaborating with AIs/LLMs can help dramatically improve upon our weaknesses, augment our thinking and brainstorming, and enable us to solve problems in novel ways.

![Co-Intelligence Book Cover](/images/co-intelligence-cover.jpg)

---

The book, for me, has one key takeaway above all others:

> Always bring AI to the table.

Couple personal examples just from today:

I prompted Claude 3.7 about PvE coop games to play with friends. I'd never really thought to try this out but it seemed worth a shot as most content on the web is clickbaiting/farming with the same old top 10-20 lists. The results were surprisingly excellent and I have more options to investigate.

I was struggling to identify parts of a piece of pool equipment and finally gave up on the traditional approach (search engines, trying to track down model numbers and manuals, etc) and thought to try AI. With a truly simple prompt, it managed to piece together the system and identify the needed parts!

So it seems that _just try it on everything_ is rather reasonable advice - the results can surprise you! And even if it doesn't pan out, it's still prompt practice.

---

> Another consequence is that we could reduce the quality and depth of our thinking and reasoning. When we use AI to generate our first drafts, we donâ€™t have to think as hard or as deeply about what we write. We rely on the machine to do the hard work of analysis and synthesis, and we donâ€™t engage in critical and reflective thinking ourselves. We also miss the opportunity to learn from our mistakes and feedback and the chance to develop our own style.

This paragraph really resonated with me as this was a major objection of mine prior to diving headfirst into AI. What am I losing or "turning over" to the machine? Are my critical thinking and analysis skills going to diminish? Will I gain enough from this tooling and endeavor to be worth that price? Or maybe nothing at all will really change? In the end, focusing on engaging with content critically and with effort is what must be done to combat these real, or perceived, threats.

This also dovetails with one of the last chapters: the idea that novices, amateurs, and those early in their career will find it incredibly hard to break into industries with heavy AI adoption. How are you supposed to gain the expertise that enables you to be of value _alongside_ the AI instead of _replaced by_ it? Is there even a way to get your metaphorical head above water?

However, this may not be a genuine concern as Mollick also cites several studies that showed the least-skilled or least-talented benefited _the most_ from using AI tools:

> Knowledge work is famous for very large differences in abilities among workers. [...] In study after study, the people who get the biggest boost from AI are those with the lowest initial abilityâ€”it turns poor performers into good performers. [...] Those who had the weakest skills benefited the most from AI, but even the highest performers gained.

Perhaps utilizing AI to do the job but also using AI to explain what it's producing will enable crossing the chasm?

---

> You need to ask: What is your vision about how AI makes work better rather than worse? 

This question hit hard as it's the same point a co-worker made to me. To poorly summarize their point, AI's a giant wave and it's here - you can either surf it or be swept under. Control it or allow it to control you. Embracing AI and leveraging it to the benefit of you and your work is more likely to "bring joy" than any alternative.

---

Mollick also has a lengthy paragraph talking about the assembly line and the ability to build, in large quantities, complex machines by decomposing that process into tiny repeatable tasks. The idea being that the summation of those tasks _is_ the complex thing which reminded me of [working on prompts](./prompt-engineering-speaking-ai-language.md), particularly [Chain of Thought](https://arxiv.org/abs/2210.03493) paradigms or a simple task check list for the AI to "follow along with" (and make loss of context windows less destructive or complex activities more resumable).
